# .github/workflows/deploy-llmops.yml
name: Deploy LLMOps Endpoint (100% Free)

on:
  push:
    branches: [ lab1 ]
  workflow_dispatch:
    inputs:
        workflow-path:
          description: 'Path to the workflow file'
          required: true
          default: '.github\workflows\lab1-workflow.yml'
jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      # 1. Checkout code
      - name: Checkout
        uses: actions/checkout@v4

      # 2. Set up Docker Buildx
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # 3. Login to GitHub Container Registry (ghcr.io)
      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # 4. Set lowercase repository name
      - name: Set lowercase repo name
        run: |
          echo "REPO_LOWER=$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV

      # 5. Build and push Docker image
      - name: Build and push
        uses: docker/build-push-action@v6
        with:
          context: llmops/Lab1-LLMOps-Pipeline/app
          push: true
          tags: ghcr.io/${{ env.REPO_LOWER }}/llmops-api:latest

      # 6. Install kind (Kubernetes IN Docker) - 100% FREE local cluster
      - name: Create Kind Cluster
        uses: helm/kind-action@v1.10.0
        with:
          cluster_name: llmops-cluster
          version: v0.23.0

      # 7. Substitute variables in deployment.yaml
      - name: Prepare Kubernetes manifests
        run: |
          # Install yq for YAML manipulation
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          
          # Split the multi-document YAML file
          cd llmops/Lab1-LLMOps-Pipeline/k8s
          yq eval 'select(di == 0)' deployment.yaml > deployment-only.yaml
          yq eval 'select(di == 1)' deployment.yaml > service-only.yaml
          
          # Update the image name in the Deployment only
          export IMAGE_NAME="ghcr.io/${{ env.REPO_LOWER }}/llmops-api:latest"
          yq eval ".spec.template.spec.containers[0].image = strenv(IMAGE_NAME)" -i deployment-only.yaml
          
          # Recombine the files
          cat deployment-only.yaml > deployment.yaml
          echo "---" >> deployment.yaml
          cat service-only.yaml >> deployment.yaml
          
          # Cleanup temp files
          rm deployment-only.yaml service-only.yaml
          
          cd ../../..
          echo "=== Updated deployment.yaml ==="
          cat llmops/Lab1-LLMOps-Pipeline/k8s/deployment.yaml
          echo ""
          echo "=== Verifying image name ==="
          yq eval 'select(di == 0) | .spec.template.spec.containers[0].image' llmops/Lab1-LLMOps-Pipeline/k8s/deployment.yaml
          echo "=== Verifying Service is intact ==="
          yq eval 'select(di == 1) | .kind' llmops/Lab1-LLMOps-Pipeline/k8s/deployment.yaml

      # 8. Create image pull secret for GHCR
      - name: Create image pull secret
        run: |
          kubectl create secret docker-registry ghcr-secret \
            --docker-server=ghcr.io \
            --docker-username=${{ github.actor }} \
            --docker-password=${{ secrets.GITHUB_TOKEN }} \
            --docker-email=${{ github.actor }}@users.noreply.github.com || true

      # 8b. Create secret for API keys (OpenAI, Azure, etc.)
      - name: Create API key secrets
        run: |
          kubectl create secret generic llmops-api-keys \
            --from-literal=OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }} \
            --from-literal=AZURE_OPENAI_KEY=${{ secrets.AZURE_OPENAI_KEY }} \
            --from-literal=AZURE_OPENAI_ENDPOINT=${{ secrets.AZURE_OPENAI_ENDPOINT }} \
            --from-literal=GROQ_API_KEY=${{ secrets.GROQ_API_KEY }} \
            --dry-run=client -o yaml | kubectl apply -f -
          echo "API secrets created/updated"

      # 9. Deploy Redis first
      - name: Deploy Redis
        run: |
          kubectl apply -f llmops/Lab1-LLMOps-Pipeline/k8s/redis.yaml
          kubectl rollout status deployment/redis -n default --timeout=120s
          echo "Redis is ready"

      # 10. Deploy API to Kind (real K8s, no cloud cost)
      - name: Deploy to Kubernetes
        run: |
          kubectl apply -f llmops/Lab1-LLMOps-Pipeline/k8s/deployment.yaml
          kubectl rollout status deployment/llmops-api -n default --timeout=300s
      
      # 9. Debug deployment if it fails
      - name: Debug deployment on failure
        if: failure()
        run: |
          echo "=== Deployment Status ==="
          kubectl get deployments
          echo "=== Pod Status ==="
          kubectl get pods -o wide
          echo "=== Pod Descriptions ==="
          kubectl describe pods -l app=llmops-api
          echo "=== Pod Logs ==="
          kubectl logs -l app=llmops-api --tail=100 || true

      # 11. Port-forward for testing
      - name: Expose service
        run: |
          kubectl port-forward svc/llmops-service 8080:80 --address 0.0.0.0 &
          sleep 5
          echo "API running at http://localhost:8080"

      # 12. Run integration tests
      - name: Test endpoint
        run: |
          pip install requests pytest
          cd llmops/Lab1-LLMOps-Pipeline
          pytest tests/test_api.py -v

      # 10. Optional: Deploy to Oracle Cloud Free Tier OKE (uncomment if you have OCI)
      # - name: Deploy to Oracle OKE (Free Forever)
      #   if: false
      #   uses: oracle-actions/setup-oci-cli@v1
      #   with:
      #     oci-config: ${{ secrets.OCI_CONFIG }}

      # 11. Success message
      - name: Success
        run: |
          echo "LLMOps API deployed successfully!"
          echo "Access at: http://localhost:8080/v1/chat/completions"
          echo "Live in GitHub Codespaces: https://github.com/codespaces"